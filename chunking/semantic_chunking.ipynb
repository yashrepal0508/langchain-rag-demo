{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcd9b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf2746e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "text = \"\"\"\n",
    "Machine learning is a subset of artificial intelligence.\n",
    "It focuses on building systems that learn from data.\n",
    "These systems improve their performance over time.\n",
    "Neural networks are a popular machine learning technique.\n",
    "They are inspired by the human brain's structure.\n",
    "Deep learning uses multiple layers of neural networks.\n",
    "Convolutional neural networks excel at image processing.\n",
    "They can identify objects in photographs.\n",
    "Natural language processing deals with text and speech.\n",
    "It enables computers to understand human language.\n",
    "Chatbots use NLP to communicate with users.\n",
    "Sentiment analysis determines emotions in text.\n",
    "Reinforcement learning trains agents through rewards.\n",
    "The agent learns by trial and error.\n",
    "It maximizes cumulative rewards over time.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b348dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: similarity with previous = 0.4330\n",
      "Sentence 2: similarity with previous = 0.3824\n",
      "Sentence 3: similarity with previous = 0.3049\n",
      "Sentence 4: similarity with previous = 0.4064\n",
      "Sentence 5: similarity with previous = 0.3178\n",
      "Sentence 6: similarity with previous = 0.5285\n",
      "Sentence 7: similarity with previous = 0.3915\n",
      "Sentence 8: similarity with previous = 0.1868\n",
      "Sentence 9: similarity with previous = 0.4806\n",
      "Sentence 10: similarity with previous = 0.4714\n",
      "Sentence 11: similarity with previous = 0.3549\n",
      "Sentence 12: similarity with previous = 0.1047\n",
      "Sentence 13: similarity with previous = 0.6324\n",
      "Sentence 14: similarity with previous = 0.2210\n",
      "\n",
      " Semantic chunks: \n",
      "\n",
      "Chunk 1: \n",
      "Machine learning is a subset of artificial intelligence. It focuses on building systems that learn from data.\n",
      "\n",
      "Chunk 2: \n",
      "These systems improve their performance over time.\n",
      "\n",
      "Chunk 3: \n",
      "Neural networks are a popular machine learning technique. They are inspired by the human brain's structure.\n",
      "\n",
      "Chunk 4: \n",
      "Deep learning uses multiple layers of neural networks. Convolutional neural networks excel at image processing.\n",
      "\n",
      "Chunk 5: \n",
      "They can identify objects in photographs.\n",
      "\n",
      "Chunk 6: \n",
      "Natural language processing deals with text and speech. It enables computers to understand human language. Chatbots use NLP to communicate with users.\n",
      "\n",
      "Chunk 7: \n",
      "Sentiment analysis determines emotions in text.\n",
      "\n",
      "Chunk 8: \n",
      "Reinforcement learning trains agents through rewards. The agent learns by trial and error.\n",
      "\n",
      "Chunk 9: \n",
      "It maximizes cumulative rewards over time.\n"
     ]
    }
   ],
   "source": [
    "sentences=[s.strip() for s in text.split(\"\\n\") if s.strip()]\n",
    "\n",
    "embeddings=model.encode(sentences)\n",
    "\n",
    "\n",
    "threshold=0.4\n",
    "chunks=[]\n",
    "\n",
    "current_chunk=[sentences[0]]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1, len(sentences)):\n",
    "    sim=cosine_similarity(\n",
    "        [embeddings[i-1]],\n",
    "        [embeddings[i]]\n",
    "    )[0][0]\n",
    "    print(f\"Sentence {i}: similarity with previous = {sim:.4f}\")\n",
    "\n",
    "\n",
    "    if sim>=threshold:\n",
    "        current_chunk.append(sentences[i])\n",
    "    else:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "        current_chunk=[sentences[i]]\n",
    "\n",
    "chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "print(\"\\n Semantic chunks: \")\n",
    "for idx, chunk in enumerate(chunks):\n",
    "    print(f\"\\nChunk {idx+1}: \\n{chunk}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c498ba6",
   "metadata": {},
   "source": [
    "#### Modular RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da021ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from langchain_core.documents import Document\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.runnables import RunnableLambda, RunnableMap\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a6ed10f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Custom Semantic Chunker With Threshold\n",
    "\n",
    "class ThresholdSematicChunker:\n",
    "    def __init__(self,model_name=\"all-MiniLM-L6-v2\",threshold=0.7):\n",
    "        self.model=SentenceTransformer(model_name)\n",
    "        self.threshold=threshold \n",
    "\n",
    "    def split(self, text: str):\n",
    "        sentences = [s.strip() for s in text.split('.') if s.strip()]\n",
    "        embeddings = self.model.encode(sentences)\n",
    "        chunks = []\n",
    "        current_chunk = [sentences[0]]\n",
    "\n",
    "        for i in range(1, len(sentences)):\n",
    "            sim = cosine_similarity([embeddings[i - 1]], [embeddings[i]])[0][0]\n",
    "            if sim >= self.threshold:\n",
    "                current_chunk.append(sentences[i])\n",
    "            else:\n",
    "                chunks.append(\". \".join(current_chunk) + \".\")\n",
    "                current_chunk = [sentences[i]]\n",
    "\n",
    "        chunks.append(\". \".join(current_chunk) + \".\")\n",
    "        return chunks\n",
    "    \n",
    "    def split_documents(self,docs):\n",
    "        result=[]\n",
    "        for doc in docs:\n",
    "            for chunk in self.split(doc.page_content):\n",
    "                result.append(Document(page_content=chunk, metadata=doc.metadata))\n",
    "\n",
    "        return result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf085048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='\\nLangChain is a framework for building applications with LLMs.\\nLangchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\\nYou can create chains, agents, memory, and retrievers.\\nThe Eiffel Tower is located in Paris.\\nFrance is a popular tourist destination.\\n')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample text\n",
    "sample_text = \"\"\"\n",
    "LangChain is a framework for building applications with LLMs.\n",
    "Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n",
    "You can create chains, agents, memory, and retrievers.\n",
    "The Eiffel Tower is located in Paris.\n",
    "France is a popular tourist destination.\n",
    "\"\"\"\n",
    "\n",
    "doc = Document(page_content=sample_text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a8e28b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='LangChain is a framework for building applications with LLMs. Langchain provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.'),\n",
       " Document(metadata={}, page_content='You can create chains, agents, memory, and retrievers.'),\n",
       " Document(metadata={}, page_content='The Eiffel Tower is located in Paris.'),\n",
       " Document(metadata={}, page_content='France is a popular tourist destination.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Chunking\n",
    "chunker=ThresholdSematicChunker(threshold=0.7)\n",
    "chunks=chunker.split_documents([doc])\n",
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d66d3ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based on the following context:\\n\\n{context}\\n\\nQuestion: {question}\\n')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prompt Template\n",
    "\n",
    "# --- 5. Prompt Template ---\n",
    "template = \"\"\"Answer the question based on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "456aa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "### VectorStore\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "embedding=HuggingFaceEmbeddings()\n",
    "vectorstore=FAISS.from_documents(chunks,embedding)\n",
    "retriever=vectorstore.as_retriever()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65e89eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework used for building applications with Large Language Models (LLMs). It provides modular abstractions to combine LLMs with tools like OpenAI and Pinecone.\n"
     ]
    }
   ],
   "source": [
    "## LLM\n",
    "llm=init_chat_model(model=\"groq:llama-3.3-70b-versatile\",temperature=0.4)\n",
    "\n",
    "### LCEL Chain With retrieval\n",
    "\n",
    "rag_chain=(\n",
    "    RunnableMap(\n",
    "        {\n",
    "        \"context\": lambda x: retriever.invoke(x[\"question\"]),\n",
    "        \"question\": lambda x: x[\"question\"],  \n",
    "        }\n",
    "    )\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# --- 8. Run Query ---\n",
    "query = {\"question\": \"What is LangChain used for?\"}\n",
    "result = rag_chain.invoke(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781ed6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99749f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c67f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d1de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f07c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ced3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
